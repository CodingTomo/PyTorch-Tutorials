{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch - Moduli.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNy8gOYc9Oc3ke1tz3Y56Qy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodingTomo/PyTorch-Tutorials/blob/master/PyTorch_Moduli.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oXYzZgmQdBz",
        "colab_type": "text"
      },
      "source": [
        "### Moduli\n",
        "\n",
        "PyTorch mette a disposizione dello sviluppatore una serie di moduli per la costruzione di reti neurali (NN). Un **modulo** non è altro che una scatoletta che, presi in input dei dati, esegue una determinata operazione. Ciò che esce dalla scatola, come output, è il risultato di questa operazione. Una NN, il più delle volte, è rappresentata da una concatenazione di questi moduli.\n",
        "\n",
        "I moduli Pytorch consentono facilmente di \n",
        "1. tenere traccia dei parametri che li compongono;\n",
        "2. salvare/caricare moduli già addestrati;\n",
        "3. azzerare efficacemente i gradienti;\n",
        "4. spostare in un solo colpo l'elaborazione da CPU a GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unX3ZG9SQWEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9Ne2tD_XfkJ",
        "colab_type": "text"
      },
      "source": [
        "Per prendere dimestichezza con la sintassi, metodi e attributi delle principali entità coinvolte, consideriamo un modulo della classe *nn* che opera una **trasformazione lineare**\n",
        "\n",
        "$$ y = xA^T+b.$$\n",
        "\n",
        "A questo scopo, supponiamo di avere un dataset di 15 osservazioni descritte da 5 variabili con associati due valori obiettivo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jxoo2R-XfNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = torch.rand(15,5)\n",
        "y = torch.rand(15, 2)\n",
        "\n",
        "linear_trasformation = torch.nn.Linear(5,2) # modulo accetta input di dimensione 5 e genera output di dimensione 2\n",
        "print('I pesi con cui il modulo è inizializzato sono: \\n ', linear_trasformation.weight)\n",
        "print('____________________________')\n",
        "print('Il bias con cui il modulo è inizializzato è: \\n ', linear_trasformation.bias)\n",
        "\n",
        "y_hat=linear_trasformation(X)\n",
        "print('____________________________')\n",
        "print('I valori predetti per y sono : \\n ', y_hat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkEHUVk5cE4G",
        "colab_type": "text"
      },
      "source": [
        "In questo esempio, la predizione così come i dati non hanno senso, tuttavia possiamo fingere che lo abbiano e calcolare sia l'errore compiuto sia il suo gradiente rispetto ai parametri della trasformazione."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WW-FYl32Xdkd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = torch.sum((y - y_hat)**2) # errore quadratico\n",
        "linear_trasformation.zero_grad() \n",
        "loss.backward()\n",
        "\n",
        "print('Gradiente della funzione di loss rispetto ai pesi: \\n ',linear_trasformation.weight.grad)\n",
        "print('____________________________')\n",
        "print('Gradiente della funzione di loss rispetto al bias: \\n ', linear_trasformation.bias.grad)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6l0gnrFni5xX",
        "colab_type": "text"
      },
      "source": [
        "Modelli realistici sono in realtà una concatenazione di più moduli. Per fare questo Pytorch mette a disposizione il *container* **Sequential**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nizGaYDAZPQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = torch.rand(15,5)\n",
        "y = torch.rand(15, 2)\n",
        "\n",
        "simple_neural_network = torch.nn.Sequential(\n",
        "    torch.nn.Linear(5, 10),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(10, 2)\n",
        ")\n",
        "\n",
        "y_hat = simple_neural_network(X) # run della rete neurale\n",
        "\n",
        "#esplorazione dei parametri \n",
        "[print(\"{:8s} shape = {}\".format(param, tensor.shape)) for param, tensor in simple_neural_network.named_parameters()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZfo7EQ5l-kt",
        "colab_type": "text"
      },
      "source": [
        "**Osservazione**: l'indice $1$ non viene stampato perchè il modulo ReLU non ha parametri, ma è l'applicazione statica dell'omonima funzione. \n",
        "\n",
        "[Ulteriori informazioni su ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9fyW2Byn8D5",
        "colab_type": "text"
      },
      "source": [
        "Possiamo costruire dei **moduli personalizzati** andando a definire una **classe** che eredita da *torch.nn.Module*. \n",
        "\n",
        "Ogni modulo personalizzato deve necessariamente implementare due metodi:\n",
        "\n",
        "1. *init()* contiene l'inizializzazione della classe padre e l'elenco dei moduli primitivi che andranno a comporre il modulo personalizzato.\n",
        "2. *forward()* contiene il piano d'esecuzione dei moduli primitivi definiti in *init*.\n",
        "\n",
        "Di seguito definiamo il modulo personalizzato che implementa *simple_neural_network* dell'esempio precedente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQWNjn_Rlrmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MySimpleNeuralNetwork(torch.nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.linear_0 = torch.nn.Linear(input_size, 10)\n",
        "        self.ReLU = torch.nn.ReLU()\n",
        "        self.linear_1 = torch.nn.Linear(10, output_size)\n",
        "\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out_0 = self.linear_0(x)\n",
        "        out_1 = self.ReLU(out_0)\n",
        "        out_2 = self.linear_1(out_1)\n",
        "        return out_2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AK8oE_C1vZmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = torch.rand(15,5)\n",
        "y = torch.rand(15, 2)\n",
        "\n",
        "y_hat = simple_neural_network(X) # run della rete neurale\n",
        "\n",
        "simple_neural_network = MySimpleNeuralNetwork(input_size = 5, output_size = 2)\n",
        "print('Panoramica generale sul modulo personalizzato: \\n',simple_neural_network)\n",
        "print('____________________________')\n",
        "[print(name, \":\\n\", p) for name, p in simple_neural_network.named_parameters()]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2P0KO_z-xZMN",
        "colab_type": "text"
      },
      "source": [
        "### Esempio di classificazione usando il dataset MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4NnT5lmxtWJ",
        "colab_type": "text"
      },
      "source": [
        "Vogliamo **classificare** delle immagini 28x28 contenenti delle cifre manoscritte usando una rete neurale. Useremo il dataset MNIST composto da 60.000 immagini di training e 10.000 immagini di test. Questo dataset è tra quelli di default nella libreria *torchvision* ed è già spezzato opportunamente in *train* e *test*.\n",
        "\n",
        "<a href=\"https://ibb.co/NL0ZwLv\"><img src=\"https://i.ibb.co/XznSmzQ/mnist.jpg\" alt=\"mnist\" border=\"0\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVQ_WJErw4iK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "import torch\n",
        "import numpy\n",
        "\n",
        "# MNIST Dataset (Images and Labels)\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        "    download=True\n",
        ")\n",
        "test_dataset = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=False, # spicifica che ci serve la parte di test\n",
        "    transform=torchvision.transforms.ToTensor()\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZGs6Dgo0brt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Il numero di immagini nel train è {}, mentre quello nel test è {}'.format(len(train_dataset),len(test_dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nmARCgK2gXJ",
        "colab_type": "text"
      },
      "source": [
        "**Osservazione**: se eseguiamo il comando \n",
        "`\n",
        "train_dataset[0]\n",
        "`\n",
        "otteniamo la prima coppia del dataset contenente l'immagine e la relativa etichetta (intero da 0 a 9). Se invece scriviamo\n",
        "`\n",
        "train_dataset[0][0].shape\n",
        "`\n",
        "otteniamo la dimensione tensoriale dell'immagine.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qfbvwQ7krNU",
        "colab_type": "text"
      },
      "source": [
        "Esercizio: Riflettere sul l'output del comando `train_dataset[0][0].shape`. Cosa cambierebbe se l'immagine fosse a colori? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU3qqcaC43fM",
        "colab_type": "text"
      },
      "source": [
        "Quando addetriamo un modello sono necessarie molte iterazioni sull'intero dataset di train. Ogni volta le osservazioni vengono mescolate e impacchettate in sottoinsiemi, detti *batch*, più o meno grossi. Questa operazione è presa in carico dal **DataLoader** di PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U3ZrYCX0xSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 100\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-FZvjfk6HyR",
        "colab_type": "text"
      },
      "source": [
        "Possiamo controllare la bontà del nostro operato eseguendo degli **assert** nel modo seguente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrECOnMB1wL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for images, labels in train_loader:\n",
        "    assert len(images) == batch_size\n",
        "    assert len(labels) == batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23NPHt0v6TgH",
        "colab_type": "text"
      },
      "source": [
        "**Osservazione**: DataLoader supporta il *multi-threading* specificando l'attributo *num_workers*.\n",
        "\n",
        "\n",
        "```\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=?)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTg7Wf2YpYYd",
        "colab_type": "text"
      },
      "source": [
        "Una **rete neurale** è formata da un insieme di strati consecutivi, detti *layer*, ognuno dei quali è composto da neuroni. Ogni neurone è connesso con tutti i neuroni dello strato immediatamente precedente e immediatamente successivo. Il **primo strato** è costruito per prendere ingresso il dataset di input e ha un numero neuroni pari al numero di variabili che descrivono un'ossevazione. L'**ultimo strato** invece genera la predizione. Per ora, pensiamo ai **layer intermedi** come a delle trasformazioni utili per analizzare nel dettaglio ogni singolo input. I parametri da addestrare in una rete neurale sono i **pesi** con cui i neuroni sono interconnessi fra loro.\n",
        "\n",
        "Nel nostro esempio il primo layer accetterà vettori di lunghezza 28x28, mentre l'ultimo genererà, per ogni vettore di input, un vettore di lunghezza $10$, dove la coodinata con valore più grande sarà l'etichetta prevista dalla rete per quella particolare istanza di input.\n",
        "\n",
        "<a href=\"https://ibb.co/GC7Znzc\"><img src=\"https://i.ibb.co/qmBH7Tk/neural-net2.jpg\" alt=\"neural-net2\" border=\"0\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvVNFYGDwEYL",
        "colab_type": "text"
      },
      "source": [
        "Per assicurarci che la rete neurale sia in grado cogliere relazioni non lineari fra le osservazioni, ogni output di ogni neurone viene trasformato tramite un funzione non lineare $\\sigma(\\cdot)$ detta **activation function**.\n",
        "\n",
        "Più precisamente, i neuroni $\\vec x_{i+1}$ del layer $i+1$ sono \"calcolati\" a partire dai neuroni $\\vec x_i$ del layer $i$ come \n",
        "\n",
        "$$ \\vec x_{i+1} = \\sigma\\left(W_{i+1} \\vec x_i + \\vec b_{i+1} \\right) $$\n",
        "\n",
        "dove $W_{i+1}$ sono i pesi della rete per ogni coppia di neuroni input/output nello strato $i+1$ e con $\\vec b_{i+1}$ il termine di bias. Osserviamo che $\\sigma$ opera elemento per elemento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3v_x68az8kZ",
        "colab_type": "text"
      },
      "source": [
        "Andiamo quindi a **definire** il nostro classificatore."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPKwtG_9wDYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as funct\n",
        "\n",
        "class MyClassifier(torch.nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(MyClassifier, self).__init__()\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.num_classes = num_classes\n",
        "        \n",
        "        self.linear_1 = torch.nn.Linear(input_size, 75)\n",
        "        self.linear_2 = torch.nn.Linear(75, 50)\n",
        "        self.linear_3 = torch.nn.Linear(50, num_classes)\n",
        "        \n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = funct.relu(self.linear_1(x))\n",
        "        out = funct.relu(self.linear_2(out))\n",
        "        out = self.linear_3(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZrKjP5I15zB",
        "colab_type": "text"
      },
      "source": [
        "Per verificare che il modulo sia ben definito proviamolo con un esempio casuale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ3gDNwE5_Pp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.rand(1, 28 * 28) \n",
        "model = MyClassifier(input_size=28 * 28, num_classes=10)\n",
        "out = model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prYl1mCTXNF5",
        "colab_type": "text"
      },
      "source": [
        "Costruiamo una funzione che ci aiuterà a capire le **performance** del nostro modello. In questo caso ci concetriamo sull'**accuratezza**, cioè il rapporto fra il numero di esempi etichettati correttamente dal modello e il numero totale degli esempi."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rsKCHdJ5JuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(model, data_loader, device):\n",
        "    with torch.no_grad(): # non ci servono i gradienti nel test. Il contesto no_grad() velocizza il processo.\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for inputs, labels in data_loader:\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "\n",
        "            # Preprocessiamo le immagini in modo che risultino dei vettori di dimensione 1 e lunghezza 28x28     \n",
        "            inputs = inputs.view(-1, 28*28)\n",
        "            \n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            \n",
        "            correct += (predicted.cpu() == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "            \n",
        "    acc = correct / total\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhN_-reO2Ymo",
        "colab_type": "text"
      },
      "source": [
        "Ora **addestriamo** il nostro classificatore."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUQ8jQ-M1loH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Copia di tutti i parametri del modello nella device corrente\n",
        "model = model.to(device)\n",
        "acc = accuracy(model, test_loader, device)\n",
        "print('La precisione del modello con pesi non addestrati è del {0:.0%}'.format(acc))\n",
        "print('____________________________')\n",
        "\n",
        "# Definiamo funzione di errore e ottimizzatore passandogli tutti i parametri del modello addestrare \n",
        "criterion = torch.nn.CrossEntropyLoss()  \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "time = numpy.array([])\n",
        "avg_loss = numpy.array([])\n",
        "acc_list = numpy.array([])\n",
        "\n",
        "# Iteriamo sull'intero dataset per 5 volte\n",
        "for epoch in range(15):\n",
        "    total_loss = 0.0\n",
        "    \n",
        "    # Iteriamo sui batch precedentemente costruiti \n",
        "    for (inputs, labels) in train_loader:\n",
        "        \n",
        "        # Copia dei dati necessari nella device corrente\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Preprocessiamo le immagini in modo che risultino dei vettori di dimensione 1 e lunghezza 28x28\n",
        "        inputs = inputs.view(-1, 28*28)\n",
        "\n",
        "        # Per ogni batch facciamo calcoliamo la predizione, l'errore e ottimizziamo\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Sommiamo l'errore di ogni batch\n",
        "        total_loss += loss.item()\n",
        "    \n",
        "    time = numpy.append(time,[epoch+1])\n",
        "    avg_loss = numpy.append(avg_loss,[total_loss/len(train_loader)])\n",
        "\n",
        "    acc = accuracy(model, test_loader, device)\n",
        "    acc_list = numpy.append(acc_list,[acc])\n",
        "\n",
        "    # Media dell'errore per epoca    \n",
        "    print('La funzione di errore dopo epoca numero {0} è del {1}'.format(epoch+1, total_loss/len(train_loader))) \n",
        "    print('La precisione del modello dopo epoca numero {0} è del {1:.0%}'.format(epoch+1,acc))\n",
        "    print('____________________________')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2yG8RX3erGW",
        "colab_type": "text"
      },
      "source": [
        "**Osservazione**: in fase di addestrmento abbiamo scelto una particolare funzione di errore. La `CrossEntropyLoss` scelta non è altro che una versione particolare della **funzione di verosimiglianza**.\n",
        "\n",
        "Di seguito una lista non esaustiva di possibili alternative.\n",
        "- `L1Loss`\n",
        "- `MSELoss`\n",
        "- `CrossEntropyLoss`\n",
        "- `NLLLoss`\n",
        "- `PoissonNLLLoss`\n",
        "- `KLDivLoss`\n",
        "- `BCELoss`\n",
        "- `...`\n",
        "\n",
        "[Ulteriori informazioni sulla funzione di verosimiglianza](https://en.wikipedia.org/wiki/Likelihood_function)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVdkGNuCSEAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def plot(x_axis,x_label,y_axis,y_label,curve_label):\n",
        "   plt.plot(x_axis, y_axis, label=curve_label)\n",
        "   plt.xlabel(x_label)\n",
        "   plt.ylabel(y_label)\n",
        "   plt.legend(shadow=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCYYdj59VOyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot(x_axis=time,x_label=\"epoch\",y_axis=avg_loss,y_label=\"average loss\",curve_label=\"Training loss\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIfkXIfe5ei6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot(x_axis=time,x_label=\"epoch\",y_axis=acc_list,y_label=\"accuracy\",curve_label=\"Test accuracy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GArCArxngEyr",
        "colab_type": "text"
      },
      "source": [
        "**Esercizio**: Aggiungere al precedente grafico l'accuratezza del training set rispetto alle epoche compiute.\n",
        "```\n",
        "Suggerimento: accuracy(model, train_loader, device)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeYbTOx0hOrS",
        "colab_type": "text"
      },
      "source": [
        "In contesti reali è fondamentale poter **salvare** i risutati ottenuti e ciò significa essere in grado di salvare il modello che quei risultati gli ha ottenuti. Nella pratica questo si traduce nel salvare i pesi già addestrati del modello ed eventualmente ricaricarli in seguito."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OgSOwlkhtKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model, \"*PATH*\\my_classifier.pt\")\n",
        "model = torch.load(\"*PATH*\\my_classifier.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}