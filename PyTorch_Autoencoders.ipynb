{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch - Autoencoders.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOuPUIzuHQLPrMdNUy63Hbe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodingTomo/PyTorch-Tutorials/blob/master/PyTorch_Autoencoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvBUMW1jkqEt",
        "colab_type": "text"
      },
      "source": [
        "### Autoencoders\n",
        "\n",
        "Un **autoencoder** è una particolare rete neurale usata per *representation learning*. Si costruisce una rete neurale prevedendo di comprimere la rappresentazione iniziale degli input. L'idea è poi quella di addestrare la rete a ricostruire il dato di partenza dal dato compresso.\n",
        "\n",
        "Questa è un'idea usata per la prima volta nell'analisi delle **componenti principali** (PCA). La PCA è infatti uno dei principali e più usati metodi di *representation learning* ed è basato su un sapiente uso dell'algebra lineare. Proprio l'uso dell'algebra lineare lo rende un metodo estremamente solido dal punto di teorico ed efficiente, ma spesso non troppo efficace in contesti reali. Il motivo è che il metodo cerca di comprimere la rappresentazione appunto in termini lineari cercando un iperpiano di dimensionalità ridotta rispetto ai dati che meglio approssima i dati stessi. Gli autoencoders possono superare il limite della linearità diventando di fatto una generalizzazione della PCA.\n",
        "\n",
        "IMMAGINE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyb_NhNTrFp1",
        "colab_type": "text"
      },
      "source": [
        "Un esempio giocattolo di **architettura** di un autoencoder è la seguente.\n",
        "\n",
        "IMMAGINE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oScKBfa7ra_-",
        "colab_type": "text"
      },
      "source": [
        "Per capire il funzionamento e la corretta implementazione di un **autoencoder** useremo ancora il dataset MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOenLXzmnmu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "import torch\n",
        "import numpy\n",
        "import torch.nn as nn\n",
        "from typing import List, Tuple\n",
        "import numpy as np\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        "    download=True\n",
        ")\n",
        "test_dataset = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=False, # specifica che ci serve la parte di test\n",
        "    transform=torchvision.transforms.ToTensor()\n",
        ")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=128, shuffle=True, pin_memory=False)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=128, shuffle=False,  pin_memory=False)\n",
        "\n",
        "print('Il numero di minibatch generati per il train è {}, mentre per il test è {}'.format(len(train_loader),len(test_loader)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUk5DmPHyttL",
        "colab_type": "text"
      },
      "source": [
        "Apriamo una piccola parentesi per quanto riguarda l'**inizializzazione** dei parametri di una rete neurale. Questa operazione, per quanto possa sembrare innoqua, è di importanza fondamentale e concorre a determinare la bontà del nostro addestramento. L'idea è che più è profonda la rete neurale più sono necessari prodotti fra matrici per arrivare da cima a fondo e viceversa. Se inizialemente gli elementi delle matrici sono troppo grandi o troppo piccoli allora gli innumerevoli prodotti tenderanno a far esplodere o svanire i parametri della rete rendendo impossibile sostenere lunghe sessioni di training. \n",
        "\n",
        "Nel nostro caso scegliamo di inizializzare i parametri con la tecnica **Kaiming** adatta alle situazioni in cui le non-linerità della rete sono ReLU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JIEk-GGIZe5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_weights(my_module):\n",
        "      for sub_module in my_module.modules():\n",
        "        if isinstance(sub_module, nn.Linear): #controlla se è m è un offetto di tipo nn.Linear\n",
        "            nn.init.kaiming_normal_(sub_module.weight, nonlinearity='relu')\n",
        "            nn.init.constant_(sub_module.bias, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4MGxwG03loY",
        "colab_type": "text"
      },
      "source": [
        "L'**encoder** è la prima delle due parti della nostra rete neurale. Si prende carico di leggere i dati di input e ridurli di dimensione in maniera progressiva. Osserviamo che il dato in uscita dall'encoder rappresenta l'**embedding** dei dati nello spazio ridotto.\n",
        "\n",
        "Nel nostro caso eseguiamo le seguenti operazioni:\n",
        "\n",
        "\n",
        "1.   riduciamo la matrice a vettore;\n",
        "2.   applichiamo una regressione lineare portando la dimesionalità da 784 a 512;\n",
        "3.   applichiamo la ReLU;\n",
        "4.   applichiamo una regressione lineare portando la dimensionalità da 512 a 256.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6_wdD1A3URV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, inp_shape: Tuple[int, int], hidden_dim: int, out_dim: int):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = nn.Sequential(nn.Flatten(),\n",
        "                                 nn.Linear(np.prod(inp_shape), hidden_dim),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Linear(hidden_dim, out_dim))\n",
        "        init_weights(self)\n",
        "\n",
        "    def forward(self, x): \n",
        "        return self.encoder(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU9TTQoj3oxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "en=Encoder(inp_shape=(28, 28), hidden_dim=512, out_dim=256)\n",
        "print(\"L'architettura dell'encoder è: \\n\", en)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6HFovnu_CdG",
        "colab_type": "text"
      },
      "source": [
        "Il **decoder** prende in input l'embedding del dato in uscita dall'encoder e cerca di ricostruire la struttura originale.\n",
        "\n",
        "Nel nostro caso eseguiamo le seguenti operazioni:\n",
        "   \n",
        "1.   applichiamo una regressione lineare portando la dimesionalità da 256 a 512;\n",
        "2.   applichiamo la ReLU;\n",
        "3.   applichiamo una regressione lineare portando la dimensionalità da 512 a 784.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvQNJ-w1737J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, inp_shape: Tuple[int, int], hidden_dim: int, out_dim: int):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.inp_shape = inp_shape\n",
        "        \n",
        "        self.decoder = nn.Sequential(nn.Linear(out_dim, hidden_dim),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Linear(hidden_dim, np.prod(inp_shape)))  \n",
        "        init_weights(self)\n",
        "        \n",
        "    def forward(self, x): \n",
        "        return torch.sigmoid(self.decoder(x)).view(x.shape[0], *self.inp_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OTvsvxx-XfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "de=Decoder(inp_shape=(28, 28), hidden_dim=512, out_dim=256)\n",
        "print(\"L'architettura dell'decoder è: \\n\", de)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su5Xvjj626ql",
        "colab_type": "text"
      },
      "source": [
        "Fondendo le due architetture si ottiene l'**autoencoder** completo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Avtc1BaF1jcL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self, inp_shape: Tuple[int, int], hidden_dim: int, out_dim: int):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.ae = nn.Sequential(Encoder(inp_shape, hidden_dim, out_dim),\n",
        "                                Decoder(inp_shape, hidden_dim, out_dim))\n",
        "        \n",
        "    def forward(self, x): \n",
        "        return self.ae(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mlPPwO823Cd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder = AutoEncoder(inp_shape=(1, 28, 28), hidden_dim=512, out_dim=256)\n",
        "autoencoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29xiBb34PTWA",
        "colab_type": "text"
      },
      "source": [
        "Definiamo un funzione che ci aiuterà a capire i **progressi** in termini di ricostruzione dell'immagine durante l'addestramento dell'autoencoder.\n",
        "\n",
        "Analizziamo la seguente riga di codice:\n",
        "\n",
        "```\n",
        "iterator = enumerate(test_loader)\n",
        "```\n",
        "\n",
        "La funzione `enumerate()` restituisce un iteratore che può essere fatto scorrere sul *test_loader* tramite la funzione `next()` o tramite un ciclo. Teniamo a mente che \n",
        "\n",
        "```\n",
        "type(next(iterator)) = tuple\n",
        "```\n",
        "In particolare, `type(next(iterator))[0] = int` e `type(next(iterator))[0] = list`.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZlTsFj93JEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Summary(valid_dl, model: nn.Module):\n",
        "\n",
        "    sample = 10\n",
        "    model.eval() \n",
        "    actuals, preds = [], []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i,(x, y) in enumerate(valid_dl.dataset):\n",
        "            actuals.append(x)\n",
        "            recon_x = model(x.unsqueeze(0).cuda()).cpu() # la funzione unsqueeze() adatta le dimensione dell'immagine x per il modello!\n",
        "            preds.append(recon_x.squeeze(0)) \n",
        "            if i + 1 == sample:\n",
        "                break\n",
        "                \n",
        "    model.train()\n",
        "\n",
        "    grid = make_grid([*actuals, *preds], pad_value=1, padding=1, nrow=sample)\n",
        "\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    plt.imshow(grid.permute(1, 2, 0))\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xI8Jpt7z4H3",
        "colab_type": "text"
      },
      "source": [
        "Definiamo il ciclo di **train**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-5zS_WB4XRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def train_ae(train_dl, \n",
        "             valid_dl,\n",
        "             model: nn.Module,\n",
        "             n_epochs: int):\n",
        "    \n",
        "    log_interval = 10\n",
        "    summary_interval = 10\n",
        "    \n",
        "    model = model.cuda()\n",
        "    \n",
        "    loss_function = nn.MSELoss(reduction='mean') #L2 loss\n",
        "    optim = torch.optim.Adam(model.parameters())\n",
        "    \n",
        "    acc_loss = 0\n",
        "    \n",
        "    print(\"Capacità ricostruttive prima dell'addestramento.\")\n",
        "    Summary(valid_dl, model)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        i = 1\n",
        "\n",
        "        for x, _ in train_dl: # le etichette non servono mai\n",
        "            optim.zero_grad()    \n",
        "            x = x.cuda()\n",
        "            x_recon = model(x)\n",
        "            loss = loss_function(x, x_recon) \n",
        "            acc_loss += loss.item()\n",
        "            loss.backward() \n",
        "            optim.step()\n",
        "            \n",
        "            if (i + 1) % log_interval == 0 and epoch == 0 and i<201:\n",
        "                print(\"Epoca {} - iterazione {}. \\n L'errore in questa iterazione è stato: {}\".format(epoch + 1, i + 1 ,acc_loss))\n",
        "                acc_loss = 0\n",
        "                \n",
        "            if (i + 1) % summary_interval == 0 and epoch == 0 and i<201:\n",
        "                Summary(valid_dl, model)\n",
        "\n",
        "            acc_loss = 0    \n",
        "            i += 1\n",
        "          \n",
        "        print(\"... sono al {:.0%} dell'addestramento\".format((epoch+1)/n_epochs))\n",
        "\n",
        "    print(\"Capacità ricostruttive a fine addestramento.\")\n",
        "    Summary(valid_dl, model)\n",
        "    print(\"Errore a fine addestramento è stato {:.50f}\".format(acc_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxOn1hlQ7tzi",
        "colab_type": "text"
      },
      "source": [
        "**Addestriamo** il modello!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFxuRVZ15ufX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ae(train_loader, test_loader, autoencoder, 20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE2_Tw5sSdhw",
        "colab_type": "text"
      },
      "source": [
        "**Esercizio**: la funzione di addestremento e quella di monitoraggio iterano in maniera diversa sui i rispettivi *dataloader*. Perchè?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH9hWy91ybB0",
        "colab_type": "text"
      },
      "source": [
        "Giustifichiamo adesso il paragone con PCA e andiamo a esplorare lo spazio **latente**. Per ragioni di visualizzazione lo ridurremo fino ad avere dimensione 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JLgip_1yZBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ae_lat = AutoEncoder(inp_shape=(1, 28, 28), hidden_dim=512, out_dim=2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vaMfG7Lc6UK",
        "colab_type": "text"
      },
      "source": [
        "Se abbiamo voglia di un caffè, addestriamo il modello da capo, altrimenti **carichiamo** i parametri dalla repository e guardiamo i risultati."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF9rAKrpc7tZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "caffe=0\n",
        "\n",
        "if caffe==1:\n",
        "  train_ae(train_loader, test_loader, ae_lat, 80)\n",
        "  torch.save(ae_lat.state_dict(),f='ae_lat_80')\n",
        "else:\n",
        "  ae_lat.load_state_dict(torch.load(\"ae_lat_80\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf8j5jEpzk2Z",
        "colab_type": "text"
      },
      "source": [
        "Una volta addestrato il nuovo autoencoder, consideriamo l'insieme di test ed eseguiamo la sola fase di **encoding** utilizzando il comando\n",
        "\n",
        "\n",
        "```\n",
        "ae_lat.ae[0](x)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eawzld0974pt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "z, labels = [], []\n",
        "for i, (x, y) in enumerate(test_loader):\n",
        "    ae_lat = ae_lat.cuda()\n",
        "    enc = ae_lat.ae[0](x.cuda()).detach() \n",
        "    enc = enc.cpu()\n",
        "    z.append(enc)\n",
        "    labels.append(y)\n",
        "z = torch.cat(z, dim=0)\n",
        "labels = torch.cat(labels, dim=0)\n",
        "\n",
        "df = pd.DataFrame({'x': z[:,0].numpy(), \n",
        "                   'y': z[:,1].numpy(),\n",
        "                   'label': labels.numpy()})\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "sns.scatterplot(x=\"x\", y=\"y\", hue=\"label\", palette=sns.color_palette(\"Paired\", 10), data=df, legend=\"full\")\n",
        "plt.title(\"Lo spazio latente dell'insieme di test dopo la fase di encoding\");"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}