{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch - Ottimizzazione.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOgSFBecEWDweAZvTSQGz0m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodingTomo/PyTorch-Tutorials/blob/master/PyTorch_Ottimizzazione.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyAixc4mIOOV",
        "colab_type": "text"
      },
      "source": [
        "### Ottimizzazione\n",
        "\n",
        "In questo notebook usiamo *autograd* di PyTorch trovare **punti critici** di funzioni. Nella pratica questo è fondamentale quando la funzione oggetto di studio è una qualche funzione di **costo** e le performance del modello dipendono da quanto si è bravi nel rintracciare il **minimo** di questa funzione."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv7g0Y30LuTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xtmq8aSBJXz5",
        "colab_type": "text"
      },
      "source": [
        "Iniziamo cercando il punto critico della funzione $f(x)=x^2$. Lo faremo implementando la *discesa del gradiente*, cioè quell'algoritmo che trova minimi locali di una funzione seguendo la direzione opposta indicata dal gradiente. Il cuore dell'algoritmo è l'aggiornamento del punto su cui calcolare il gradiente successivo, ovvero: $$x_{t+1} = x_{t} - \\lambda \\nabla_x f (x_t),$$ dove $\\lambda$ è un parametro che controlla la lunghezza del passo da $x_t$ a $x_{t+1}$ ed è detto *learning rate*.\n",
        "\n",
        "**Osservazione**: ricordiamo che il gradiente di una funzione calcolato in un punto $x_0$ è un vettore ortogonale alla curva di livello della funzione passante per quel punto e la cui direzione mira al massimo locale della funzione. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjWIZCiAZF0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f(x):\n",
        "  return x ** 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdPYKOh7ZOqe",
        "colab_type": "text"
      },
      "source": [
        "**Soluzione 1**: aggiornamento con variabile d'appoggio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhYKlUiLcXyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_0=3.0\n",
        "l_rate=0.1\n",
        "\n",
        "x = torch.tensor([x_0], requires_grad=True)\n",
        "y = f(x)\n",
        "\n",
        "for i in range(5):\n",
        "  y.backward()\n",
        "\n",
        "  print('Il valore della derivata di f in {} è {}'.format(x.detach().numpy(),x.grad.detach().numpy()))\n",
        "  print('Il valore atteso della derivata di f in {} è {}'.format(x.detach().numpy(), 2*x.detach().numpy() ))\n",
        "\n",
        "  x_next = (x - l_rate * x.grad).detach()\n",
        "  x = x_next.detach().requires_grad_(True)\n",
        "\n",
        "  y = f(x)\n",
        "\n",
        "  print('Il valore di f in {} è {}'.format(x.detach().numpy(),y.detach().numpy()))\n",
        "\n",
        "  print( ' \\n --- fine iterazione numero {} ----  \\n '.format(i+1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjOOKietZb6G",
        "colab_type": "text"
      },
      "source": [
        "**Soluzione 2**: aggiornamento *inplace*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lrl1IMdjHdoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_0=3.0\n",
        "l_rate=0.1\n",
        "\n",
        "x = torch.tensor([x_0], requires_grad=True)\n",
        "y = f(x)\n",
        "\n",
        "for i in range(5):\n",
        "  y.backward()\n",
        "\n",
        "  print('Il valore della derivata di f in {} è {}'.format(x.detach().numpy(),x.grad.detach().numpy()))\n",
        "  print('Il valore atteso della derivata di f in {} è {}'.format(x.detach().numpy(), 2*x.detach().numpy() ))\n",
        "\n",
        "  with torch.no_grad():\n",
        "    x -= l_rate * x.grad \n",
        "  \n",
        "  #x = (x - l_rate * x.grad).detach().requires_grad_(True) # funziona al posto del contesto torch.no_grad\n",
        "\n",
        "  x.grad.zero_()\n",
        "  y = f(x)\n",
        "\n",
        "  print('Il valore di f in {} è {}'.format(x.detach().numpy(),y.detach().numpy()))\n",
        "\n",
        "  print( ' \\n --- fine iterazione numero {} ----  \\n '.format(i+1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wesv48kjj_QQ",
        "colab_type": "text"
      },
      "source": [
        "**Osservazione**: L'aggiornamento *inplace* di $x$ è particolarmente delicato. Vogliamo che il nuovo tensore non contenga la storia dell'aggiornamento e che il gradiente pre-esistente non si accumuli.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9lgxb0-hnaY",
        "colab_type": "text"
      },
      "source": [
        "**Esercizio**: Capire che differenza c'è tra le due soluzioni proposte. Variare il parametro *l_rate* e capire che impatti ha sull'algoritmo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBoMKQA6m49J",
        "colab_type": "text"
      },
      "source": [
        "Nella pratica non è necessario implementare algoritmi come la discesa del gradiente poichè PyTorch implemeta la classe **optim** che contiene molte procedure di ottimizzazione fra cui quello appena visto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxPPHP7JL6ge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "parameters = [x] # in un caso reale contiene un iterabile con i parametri del modello da ottimizzare \n",
        "\n",
        "optimizer = optim.SGD(parameters, lr=0.01, momentum=0.9)\n",
        "optimizer = optim.Adam(parameters, lr=0.01)\n",
        "optimizer = optim.Adadelta(parameters, lr=0.01)\n",
        "optimizer = optim.Adagrad(parameters, lr=0.01)\n",
        "optimizer = optim.RMSprop(parameters, lr=0.01)\n",
        "optimizer = optim.LBFGS(parameters, lr=0.01)\n",
        "\n",
        "# ... elenco non esaustivo!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C3d9p7ch10c",
        "colab_type": "text"
      },
      "source": [
        "Utilizzando la stessa funzione $f$ degli esempi precedenti, sfuttiamo l'implementazione dell'algoritmo **SGD** di optim per cercare il minimo di $f$.\n",
        "\n",
        "[Ulteriori informazioni sull'algoritmo SDG](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqccOQB0hmYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x0 = 3\n",
        "l_rate=0.1\n",
        "\n",
        "x = torch.tensor([x_0], requires_grad=True)\n",
        "y = f(x)\n",
        "\n",
        "optimizer =  optim.SGD([x], lr=l_rate, momentum=0.3) # nel caso esempio passiamo la nostra unica variabile\n",
        "\n",
        "for i in range(10):\n",
        "    \n",
        "  y.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  y=f(x)\n",
        "\n",
        "  print('Il valore di f in {} è {}'.format(x.detach().numpy(),y.detach().numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxUdvIv4i-xf",
        "colab_type": "text"
      },
      "source": [
        "Spesso nella pratica può essere utile aggiustare il **leaning-rate** dinamicamente. Pytorch offre diverse funzionalità per controllare questo parametro in fase di addestramento.\n",
        "\n",
        "Di seguito un elenco non esaustivo.\n",
        "```\n",
        "optim.lr_scheduler.LambdaLR\n",
        "optim.lr_scheduler.ExponentialLR\n",
        "optim.lr_scheduler.MultiStepLR\n",
        "optim.lr_scheduler.StepLR\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Vsx5nrJpL33",
        "colab_type": "text"
      },
      "source": [
        "Utilizzando la stessa funzione $f$ degli esempi precedenti sfuttiamo l'implementazione dell'algoritmo **SGD** e dello scheduler **ExponentialLR**.\n",
        "\n",
        "L'aggiornamento di questo scheduler segue la legge: $$\\lambda_{t}=\\lambda_{0}*\\gamma^t,$$\n",
        "dove $\\lambda_{t}$ è il learning rate al passo $t$ e $\\gamma$ un parametro nell'intervallo $(0,1)$ che controlla la velocità di decadimento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyU1juUgjlrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x0 = 8.0\n",
        "l_rate = 0.3\n",
        "\n",
        "x = torch.tensor([x0]).requires_grad_()\n",
        "optimizer = optim.SGD([x], lr=l_rate)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, 0.9)\n",
        "\n",
        "for i in range(10):\n",
        "  \n",
        "    y.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    y = f(x)\n",
        "\n",
        "    print('Il valore di f in {} è {} e learning rate attuale vale {}'\n",
        "      .format(x.detach().numpy(),y.detach().numpy(),optimizer.param_groups[0]['lr']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLO9zJMAwSZy",
        "colab_type": "text"
      },
      "source": [
        "Un **esempio** completo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iGKjY7Lsu1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import numpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsjoTgxcnvuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def g(x):\n",
        "    return x ** 2 / 20 + x.sin().tanh()\n",
        "\n",
        "def plot(coord_x,coord_y):\n",
        "   x_points = torch.linspace(-10, 10, 500)\n",
        "   y_points = x_points ** 2 / 20 + x_points.sin().tanh()\n",
        "   plt.scatter(coord_x, coord_y, color='red')\n",
        "   plt.plot(x_points.numpy(), y_points.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eya7TF9mujqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_0=8.0\n",
        "l_rate=0.4\n",
        "\n",
        "x=torch.tensor([x_0], requires_grad=True)\n",
        "y=g(x)\n",
        "\n",
        "coord_x=numpy.array([x_0])\n",
        "coord_y=numpy.array([y.detach().numpy()])\n",
        "\n",
        "optimizer = optim.Adam([x], lr=l_rate)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, 0.9)\n",
        "\n",
        "for i in range(50):\n",
        "  y.backward()\n",
        "  optimizer.step()\n",
        "  scheduler.step()\n",
        "  optimizer.zero_grad()\n",
        "  y=g(x)\n",
        "\n",
        "  coord_x = numpy.append(coord_x, [x.detach().numpy()])\n",
        "  coord_y = numpy.append(coord_y, [y.detach().numpy()])\n",
        "\n",
        "plot(coord_x,coord_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJ7JWjy51P40",
        "colab_type": "text"
      },
      "source": [
        "**Esercizio**: ripetere l'esempio precedente usando una funzione a piacere definita da $\\mathbb{R}^2$ in $\\mathbb{R}$ e visualizzarne il grafico in tre dimensioni."
      ]
    }
  ]
}