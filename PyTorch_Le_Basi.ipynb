{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch - Le Basi.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMh/bzwF6G4VDub2TTZM+JV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodingTomo/PyTorch-Tutorials/blob/master/PyTorch_Le_Basi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EneNL2Jl84c",
        "colab_type": "text"
      },
      "source": [
        "**Torch** è un *framework* open-source sviluppato da Facebook per implementare modelli di Machine Learning e opera tramite l'utilizzo di tensori. \n",
        "\n",
        " Un **vettore** rispetto ad un fissato sistema di riferimento è un **tensore** di dimensione 1. Una **matrice** nelle stesse condizioni è un **tensore** di dimensione 2 e così via. \n",
        " A questo concetto intuitivo di tensore si affianca, in matematica, una definizione più rigorosa che non necessita di specificare un particolare sistema di riferimento (base).\n",
        "\n",
        " [Per ulteriori informazioni sul concetto di tensore](https://en.wikipedia.org/wiki/Tensor)\n",
        "\n",
        "\n",
        " ### PyTorch\n",
        "Pytorch è una libreria Python, simile a NumPy, per sviluppare modelli statistici e di ML. I due aspetti principali che la differenziano da Numpy sono:\n",
        "- permettere uso di GPU;\n",
        "- permettere il calcolo differenziale.\n",
        "\n",
        "Questo notebook e i successivi sono pensati per essere utilizzati su google **Colab**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JDvKUk5lbgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHhIXO-2uapG",
        "colab_type": "text"
      },
      "source": [
        "Definiamo di seguito due tensori di dimensione $1$ e $2$ rispettivamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXCoIM0N5Xp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = torch.tensor([1, 2, 3, 4, 5])\n",
        "print('Questo è un tensore di dimensione 1: ', X.numpy())\n",
        "print('-'*70)\n",
        "print(\"La 'lunghezza' del tensore nella sua unica dimensione è: \", X.numpy().shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AECzwf8s7cvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = torch.tensor([[1,2,3],[4,5,6]])\n",
        "print('Questo è un tensore di dimensione 1: \\n', Y.numpy())\n",
        "print('-'*70)\n",
        "print(\"Le 'lunghezze' del tensore nelle sue due dimensioni sono: \", Y.numpy().shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6OkPk-jvOrN",
        "colab_type": "text"
      },
      "source": [
        "**Esercizio**: costruire un tensore con dimensione $[3,3,2]$ e verificare cosa cambia se rimuoviamo il *cast* che trasforma la nostra istanza Pytorch in numpy. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6Nh9mACw8G5",
        "colab_type": "text"
      },
      "source": [
        "**Pytorch** è molto simile anche sintatticamente a **numpy**. Vediamo qualche esempio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFt0yhanxEnr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.eye(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNn7V6hoxNNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.eye(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSq_lilhxSuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.arange(0,10,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOXB0FaLxhxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.arange(0,10,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0onNHkXydln",
        "colab_type": "text"
      },
      "source": [
        "Molto spesso non molto utile definire tensori scrivendone il contenuto esplicitamente. Esistono molte funzioni che permettono di scrivere particolari tensori usando un solo comando. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bnrwr71Hx-jj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.zeros(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZZijLYd2vTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.ones((2,2,2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6iM0r0522fv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.empty((2,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5AMOO0b3ByT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.rand(2,2,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee-qGfGm7bTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.linspace(1,10,5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-syaiAhvTgJW",
        "colab_type": "text"
      },
      "source": [
        "Di seguito una serie di metodi o attributi utili a recuperare la **struttura** di un tensore."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH2n0-UcTfBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.Tensor([[0,1,2], [3,4,5]])\n",
        "\n",
        "print(\"x.shape : \", (x.shape,))\n",
        "print('-'*70)\n",
        "print(\"x.size() : \",(x.size(),))\n",
        "print('-'*70)\n",
        "print(\"x.size(1) : \", x.size(1))\n",
        "print('-'*70)\n",
        "print(\"x.dim() : \",x.dim())\n",
        "print('-'*70)\n",
        "print(\"x.numel(): \", x.numel())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwhnYtr8QxHj",
        "colab_type": "text"
      },
      "source": [
        "In generale in PyTorch le **operazioni** si concatenano l'una con l'altra. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w41BDG7FRmA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = torch.rand(3, 2)\n",
        "print(X.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfxavVyJRsRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X.exp()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCjh0-hwSbVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X.exp() + 2).sqrt() - 2 * X.log().sigmoid()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rQCdHBMSYEK",
        "colab_type": "text"
      },
      "source": [
        "Tuttavia esiste la possibità di eseguire i conti scrivendo in forma \"funzionale\" il calcolo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10DVAEnnTKCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.exp(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2HMmGuETeeX",
        "colab_type": "text"
      },
      "source": [
        "**Esercizio**: portare in forma \"funzionale\" (dove possibile) il seguente conto:\n",
        "```\n",
        "(X.exp() + 2).sqrt() - 2 * X.log().sigmoid()\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUInHb8TUbQ6",
        "colab_type": "text"
      },
      "source": [
        "Anche le operazioni di **aggregazione** hanno una sintassi simile."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HusRhLgrUheM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=torch.rand(3, 2)\n",
        "print(X.numpy())\n",
        "print('-'*70)\n",
        "print('La somma è :', X.sum())\n",
        "print('-'*70)\n",
        "print('La media è :', X.mean())\n",
        "print('-'*70)\n",
        "print('La norma 1 è :', X.norm(p=2))\n",
        "print('-'*70)\n",
        "print('Il massimo per ogni riga è : \\n', X.max(dim=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKIBz7y8W8eS",
        "colab_type": "text"
      },
      "source": [
        "**Esercizio** Convincersi che nell'esempio precedente vale sempre: \n",
        "\n",
        "```\n",
        "X.sum() = X.norm(p=1) > X.norm(p=2)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3VfqTO1uLc0",
        "colab_type": "text"
      },
      "source": [
        "Le pricipali **operazioni** tra tensori di dimensione 2 (matrici) sono già implementate all'interno di PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pYgFv0Auy3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = torch.rand(2, 3)\n",
        "print('La matrice Y : \\n',  Y.numpy())\n",
        "print('-'*70)\n",
        "print('La trasposta di Y : \\n', Y.t().numpy())\n",
        "print('-'*70)\n",
        "print('Il prodotto righe per colonne fra Y e Y.t() : \\n', (Y @ Y.t()).numpy())\n",
        "print('-'*70)\n",
        "print('Il determinante di Y @ Y.t() : \\n', (Y @ Y.t()).det().numpy())\n",
        "print('-'*70)\n",
        "print('Inversa di Y @ Y.t() : \\n', (Y @ Y.t()).inverse().numpy())\n",
        "print('-'*70)\n",
        "print('Informazioni spettrali di Y @ Y.t() : \\n', (Y @ Y.t()).eig())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-QsGykr6awc",
        "colab_type": "text"
      },
      "source": [
        "**Esercizio**: Capire come eseguire il prodotto elemento per elemento di due matrici. Che vincolo devono soddisfare le due matrici?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kWFTA_F8IxU",
        "colab_type": "text"
      },
      "source": [
        "Esistono alcuni operatori che non vanno a modificare l'oggetto su cui operano. E' fondamentale capire ciò che, si potrebbe dire, agisce per **riferimento** o per **valore**. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux2-fSMT6Zp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=torch.eye(3)\n",
        "X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5z0wEai-e7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Sommo 5 elemento per elemento ad X usando add() : \\n', X.add(5).numpy())\n",
        "print('-'*70)\n",
        "print('Stampo X: \\n', X.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZeKeMtE_fyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Sommo 5 elemento per elemento ad X usando add_() : \\n', X.add_(5).numpy())\n",
        "print('-'*70)\n",
        "print('Stampo X: \\n', X.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsH1fKjjBhTl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Ancora più sottile è la differenza tra i seguenti blocchi di codice. Chiara se si pensa alle **variabili** come ad **allocazioni di memoria** fisiche sulla macchina."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5B7VAc8__64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = torch.ones(1)\n",
        "\n",
        "A_copia = A\n",
        "A = A + 1\n",
        "\n",
        "print('A e A_copia valgono rispettivamente: ', A.numpy(), A_copia.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myhv4doZAAB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = torch.ones(1)\n",
        "\n",
        "A_copia = A\n",
        "A += 1\n",
        "\n",
        "print('A e A_copia valgono rispettivamente: ', A.numpy(), A_copia.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2NuBgvY_7SI",
        "colab_type": "text"
      },
      "source": [
        "**Esercizio**: Quante celle di memoria sono occupate nell'ultimo blocco? Quante nel penultimo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq5gK5Ij-ZIz",
        "colab_type": "text"
      },
      "source": [
        "Selezionare specifiche **righe** e/o **colonne** è molto facile usando opportunamente gli indici e l'operatore **:**\n",
        "\n",
        "Osservare che la numerazione parte da 0. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJp-vmGoMuvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = torch.randint(100, (5, 5))\n",
        "A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a1HmyHTMu7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A[0,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96ofFnpoMu5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A[:, 2:4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKqsZKMDMu3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A[2:, :3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h2LsG2AMena",
        "colab_type": "text"
      },
      "source": [
        "**Esercizio**: estrarre dal tensore X definito come:\n",
        "\n",
        "```\n",
        "X = torch.arange(40).view(5,8)\n",
        "```\n",
        "il vettore\n",
        "$ \\begin{bmatrix}\n",
        "17 & 19 & 21 & 23 \\\\\n",
        "\\end{bmatrix}  $\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQRTzinVQjI4",
        "colab_type": "text"
      },
      "source": [
        "Nella pratica sono molto utili le funzioni di **ridimensionamento** di un tensore.\n",
        "\n",
        "La funzione `view()` è l'quivalente di `reshape()` di numpy con la differenza che non rialloca l'oggetto, ma tiene traccia solo del metadato."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmPFsS1CQv1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = torch.tensor([1, 2, 3, 4, 5, 6])\n",
        "print('Tensore di partenza : ', X.numpy())\n",
        "print('-'*70)\n",
        "Y = X.view(2, 3)  \n",
        "print('Ridimensionato : \\n' ,Y.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wXXN-FsQwA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Z = X.view(-1, 2) # inferisce in automatico la prima delle due dimensioni\n",
        "print('Ridimensionato : \\n' ,Z.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s8rqKbWS8mO",
        "colab_type": "text"
      },
      "source": [
        "Altre funzioni di ridimensionamento sono `expand()`, `squeeze()` e `unsqueeze()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUrGV4DUQv_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = torch.ones(5) # dimensione 1\n",
        "Y = Y.view(-1, 1) # dimensione 2\n",
        "Y, Y.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E30ESsPATSXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y.expand(5, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkqeYkBPTSlW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = torch.eye(4)\n",
        "Y = X[3:, :]\n",
        "Y, Y.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Repsw-WXTSjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = Y.squeeze()\n",
        "Y, Y.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SksybBqnTShO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = Y.unsqueeze(1)\n",
        "Y, Y.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn19awQCSB7c",
        "colab_type": "text"
      },
      "source": [
        "**Esercizio**: creare il seguente tensore:\n",
        "\n",
        "\n",
        "$$ \\begin{bmatrix}\n",
        "1 & 0.5 & 0.5   \\\\ 0.5 & 1 & 0.5 \\\\ 0.5 & 0.5 & 1\n",
        "\\end{bmatrix}  $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAwlm-GLUREx",
        "colab_type": "text"
      },
      "source": [
        "**Esercizio**: creare il seguente tensore:\n",
        "\n",
        "$$ \\begin{bmatrix}\n",
        "2 & 2 & 2 & 2 & 2 \\\\\n",
        "4 & 4 & 4 & 4 & 4 \\\\\n",
        "6 & 6 & 6 & 6 & 6 \\\\\n",
        "8 & 8 & 8 & 8 & 8\n",
        "\\end{bmatrix}  $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLS_7JKZplsO",
        "colab_type": "text"
      },
      "source": [
        "Le **maschere** sono molto utili per imporre condizioni direttamente sugli elementi che compongono un tensore."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wpc1fLNTH_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = torch.randint(100, (2, 5, 3))\n",
        "print('Tensore: \\n', X.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQNgcQKo7pvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask = (X > 25) & (X < 75)\n",
        "print('Una possibile maschera per X: \\n', mask)\n",
        "# mask = (X == 25) | (X > 60) #un'altra possibile maschera."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtZQhCMmwSl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X[mask] # Ritorna in un tensore 1 dimensionale tutti gli elementi che soddisfano la condizione"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNq5yTKBxvgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask.sum() # Ritorna il numero di elementi che soddisfano la condizione"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w61ANOHizLS-",
        "colab_type": "text"
      },
      "source": [
        "**Esercizio**: A partire dal tensore X definito come:\n",
        "\n",
        "```\n",
        "X = torch.tensor([[1, 0, 2], [4, 6, 0], [0, -7, 1]]),\n",
        "```\n",
        "usare le maschere per rispondere alle seguenti domande.\n",
        "\n",
        "1.   Quanti elementi sono negativi?\n",
        "2.   Dopo aver trovato la media aritmetica degli elementi di $X$, calcolare la somma degli elementi di $X$ il cui valore è superiore alla media calcolata.\n",
        "3. Sostituire $0$ a tutti gli elementi di X che non sono compresi nell'intervallo $[1,3]$.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA0ou8fd200q",
        "colab_type": "text"
      },
      "source": [
        "Le operazioni di **cast** fra tipi diversi di tensori o fra oggetti Pytorch e numpy sono immediati."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yclhk8UjyEeS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = 4 * torch.rand((2,4))\n",
        "Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxAOTg1B0vgs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y.to(torch.int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCB89Kus3M-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.LongTensor([1, 2]) + torch.FloatTensor([1.1, 2.2]) # supporta l'autocast se necessario"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYOm-9k737cD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.random.random((5,3)) # da numpy a Torch\n",
        "Y=torch.from_numpy(X)\n",
        "Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FqKzdGd4L33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = Y.numpy() # da Torch a numpy\n",
        "X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjGB9fK6Pn5O",
        "colab_type": "text"
      },
      "source": [
        "**CUDA** (acronimo di Compute Unified Device Architecture) è un'architettura hardware per **l'elaborazione parallela** creata da NVIDIA. Tramite l'ambiente di sviluppo per CUDA, i programmatori di software possono scrivere applicazioni capaci di eseguire calcolo parallelo sulle GPU delle schede video NVIDIA.\n",
        "\n",
        "[Ulteriori informazioni su CUDA](https://en.wikipedia.org/wiki/CUDA)\n",
        "\n",
        "Pytorch è in grado di rilevare è disponibile una GPU e in caso positivo sfruttarla."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvcF9AXn4lmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.is_available() \n",
        "# Se la risposta è false, andare nella barra in alto, quindi Runtime -> Change runtime type -> Hardware accelerator = GPU e ricaricare le librerie"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXQnp9A2P_AY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.device_count() # numero di GPU disponibili"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3uXe2zSTh1d",
        "colab_type": "text"
      },
      "source": [
        "Il modo migliore per spostare un tensore da una *device* ad un'altra è la funzione `to()` alla quale è necessario passare un oggetto di tipo *torch.device object*. Un **torch.device object** è un oggetto che rappresenta il *device* su cui il tesore è definito o sarà allocato."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbNlKBzH44g6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.Tensor([[1,2,3], [4,5,6]])\n",
        "\n",
        "cpu = torch.device('cpu')\n",
        "cuda_0 = torch.device('cuda:0') # si indicizza da 0\n",
        "\n",
        "x = x.to(cpu)\n",
        "print('Il tensore è posizionato su:', x.device)\n",
        "x = x.to(cuda_0)\n",
        "print('Il tensore è posizionato su:', x.device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDgkzqGnR_rk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "x = x.to(device)  # In questo modo se siamo su una macchina con GPU bene, altrimenti si va su CPU\n",
        "print(x.device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5HZUz7PUy3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = torch.Tensor([[1,1,1], [1,1,1]])\n",
        "print('Il tensore y è posizionato in: ', y.device)\n",
        "print('Il tensore x è posizionato in: ', x.device)\n",
        "\n",
        "# z = x+y # Questo comando va in errore ogni volta che x e y sono posizionati su device diverse!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffbhDf_YXSup",
        "colab_type": "text"
      },
      "source": [
        "Un **confronto** fra le prestazioni di CPU e GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXLPO04iU-YO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = torch.rand(100, 1000, 1000) # pensare a 100 matrici 1000x1000\n",
        "B = A.cuda()\n",
        "A.size()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND1ydB_7WR6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%timeit -n 3 torch.bmm(A, A) # prodotto tensore di A con se stesso eseguito 3 volte su CPU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTu8lCxWWuEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%timeit -n 30 torch.bmm(B, B) # prodotto tensore di B con se stesso eseguito 30 volte su GPU"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}