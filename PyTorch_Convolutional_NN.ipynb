{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch - Convolutional NN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMIPzZNJY+DH1qxq9iM5klt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodingTomo/PyTorch-Tutorials/blob/master/PyTorch_Convolutional_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfabJpR53E09",
        "colab_type": "text"
      },
      "source": [
        "### Convolutional Neural Networks\n",
        "\n",
        "Le reti neurali convoluzionali (CNN) sono un particolare tipo di reti neurali profonde la cui caratteristica è quella di operare sui dati principalmente tramite l'operazione di **convoluzione**.\n",
        "\n",
        "La convoluzione è un operazione estramemente potente usata in vari settori della matematica, della fisica e dell'ingegneria. \n",
        "\n",
        "[Ulteriori informazioni sulla convoluzione](https://en.wikipedia.org/wiki/Convolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjTb12mb9gH2",
        "colab_type": "text"
      },
      "source": [
        "Parlare in maniera diffusa della definizione e delle varie proprietà della convoluzione richiederebbe molto tempo, quindi cerchiamo solo di capire cosa avviene operativamente all'interno di una CNN che lavora con delle di immagini.\n",
        "\n",
        "Supponiamo di avere:\n",
        "*   una matrice di input $A$ di dimensione 5x5;\n",
        "*   una matrice di filtro $B$ di dimensione 3x3.\n",
        "\n",
        "La convoluzione fra $A$ e $B$ significa calcolare una sorta di prodotto scalare di A con B mentre B \"scorre\" su A. La seguente immagine è molto chiara.\n",
        "\n",
        "<p>\n",
        "<img src=\"Immagini/conv.jpg\" width=\"250\" style=\"margin-left: auto;margin-right: auto;display: block;\" />\n",
        "</p>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDJy3Jf81sgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "from collections import OrderedDict\n",
        "from matplotlib import pyplot as plt \n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.set_printoptions(precision=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVyYWhFnTBk4",
        "colab_type": "text"
      },
      "source": [
        "Per eseguire una convoluzione tra matrici sfuttiamo la funzione\n",
        "`\n",
        "torch.nn.functional.conv2d\n",
        "`.\n",
        "\n",
        "Osserviamo che la funzione richiede che il tensore di input e il filtro o *kernel* debbano avere dimensione $4$. In particolare, tali dimensioni rappresentano\n",
        "\n",
        "*   **Input**: Batch size, Num channels, Input height, Input width;\n",
        "*   **Filtro**: Num output channels, Num input channels, Filter height, Filter width.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgrehSbT1-P3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input = torch.Tensor([[3,3,2,1,0], [0,0,1,3,1], [3,1,2,2,3], [2,0,0,2,2], [2,0,0,0,1]]).view(1,1,5,5)\n",
        "kernel = torch.Tensor([[0,1,2],[2,2,0],[0,1,2]]).view(1,1,3,3)\n",
        "\n",
        "conv_result = torch.nn.functional.conv2d(input, kernel)\n",
        "print(\"Il risultato della convoluzione del kernel sull'input è: \\n {}\".format(conv_result.squeeze().numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCS20swbXrgZ",
        "colab_type": "text"
      },
      "source": [
        "L'operazione di convoluzione è spesso seguita da un operazione di **pooling**. Questa operazione ha lo scopo di sintetizzare le feature rilevate nell'input a seguito della funzione di attivazione susseguente allo strato convolutivo.\n",
        "\n",
        "IMMAGINE\n",
        "\n",
        "*In all cases, pooling helps to make the representation become approximately invariant to small translations of the input. Invariance to translation means that if we translate the input by a small amount, the values of most of the pooled outputs do not change.* \n",
        "\n",
        "[DeepLearningBook](http://www.deeplearningbook.org)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhV1N7xRnAox",
        "colab_type": "text"
      },
      "source": [
        "Nell'esempio che segue operiamo in *MaxPool* 2x2 su `conv_result`. In pratica con un scorriamo una matrice senza pesi sull'input e selezioniamo sempre il massimo fra i $4$ numeri sezionati."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbQbu-fClGob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pool_result = torch.nn.functional.max_pool2d(conv_result, kernel_size=(2,2), stride=1)\n",
        "print(\"Il risultato della convoluzione del kernel sull'input è: \\n {}\".format(pool_result.squeeze().numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBYa-id9n9Bw",
        "colab_type": "text"
      },
      "source": [
        "Negli esempi successivi vediamo come particolari **filtri** operano per convoluzione su **immagini** reali."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LXLfVHGksZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "image = Image.open(\"Immagini/staccionata.jpg\").convert('L')\n",
        "print(image.size)\n",
        "image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_egYYJPtnj-o",
        "colab_type": "text"
      },
      "source": [
        "**Osservazione**: la funzione `convert('L')` trasforma l'immagine in bianco e nero. La trasformazione è una somma pesata dei canali RGB di input.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WdTuyTSms6f",
        "colab_type": "text"
      },
      "source": [
        "Definiamo di seguito tre **filtri** e operiamo la convoluzione con la nostra immagine di input. I filtri hanno uno **scopo** ben preciso: sfuocare l'immagine, evidenziare linee orizzontali e evidenziare linee verticali."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXdPxaEnlNLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.transforms.functional import to_tensor, to_pil_image\n",
        "\n",
        "image_tensor = to_tensor(image)\n",
        "input = image_tensor.unsqueeze(0)\n",
        "kernel_out_focus = torch.Tensor([[[\n",
        "                         [1/25,1/25,1/25,1/25,1/25],\n",
        "                         [1/25,1/25,1/25,1/25,1/25],\n",
        "                         [1/25,1/25,1/25,1/25,1/25],\n",
        "                         [1/25,1/25,1/25,1/25,1/25],\n",
        "                         [1/25,1/25,1/25,1/25,1/25]\n",
        "                         ]]])\n",
        "\n",
        "kernel_hor=torch.Tensor([[[\n",
        "                         [-1,-1,-1],\n",
        "                         [0,0,0],\n",
        "                         [1,1,1]\n",
        "                         ]]])\n",
        "\n",
        "kernel_vert=torch.Tensor([[[\n",
        "                         [-1,0,1],\n",
        "                         [-1,0,1],\n",
        "                         [-1,0,1]\n",
        "                         ]]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osX6M-nG_QPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = torch.nn.functional.conv2d(input, kernel_out_focus)\n",
        "norm_out = (out - out.min()) / (out.max() - out.min())\n",
        "to_pil_image(norm_out.squeeze())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VrtvVMnYIfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = torch.nn.functional.conv2d(input, kernel_hor)\n",
        "norm_out = (out - out.min()) / (out.max() - out.min())\n",
        "to_pil_image(norm_out.squeeze())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4tB-vp3YLX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = torch.nn.functional.conv2d(input, kernel_vert)\n",
        "norm_out = (out - out.min()) / (out.max() - out.min())\n",
        "to_pil_image(norm_out.squeeze())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ev0eQOnuIyZ",
        "colab_type": "text"
      },
      "source": [
        "### Esempio di classificazione usando il dataset MNIST\n",
        "\n",
        "Come nel precedente tutorial, riproviamo a classificare le immagini delle cifre manoscritte del dataset MNIST usando questa volta una rete convoluzionale. L'architettura della rete che useremo è una verisione modificata della famosa [LeNet-5](https://en.wikipedia.org/wiki/Convolutional_neural_network)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wfgeKGqt9WY",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "**Architettura**\n",
        "\n",
        "+ Strati convoluzionali:\n",
        "\n",
        "\n",
        "| Layer       | Name | Input channels | Output channels | Kernel | stride |\n",
        "| ----------- | :--: | :------------: | :-------------: | :----: | :----: |\n",
        "| Convolution |  conv_0  |       1        |        6        |  5x5   |   1    |\n",
        "| ReLU        |      |       6        |        6        |        |        |\n",
        "| MaxPooling  |  pool_0  |       6        |        6        |  2x2   |   2    |\n",
        "| Convolution |  conv_1  |       6        |       16        |  5x5   |   1    |\n",
        "| ReLU        |      |       16       |       16        |        |        |\n",
        "| MaxPooling  |  pool_1  |       16       |       16        |  2x2   |   2    |\n",
        "| Convolution |  conv_2  |       6        |       120       |  5x5   |   1    |\n",
        "| ReLU        |      |      120       |       120       |        |        |\n",
        "\n",
        "\n",
        "+ Strati *fully connected*:\n",
        "\n",
        "| Layer      | Name | Input size | Output size |\n",
        "| ---------- | :--: | :--------: | :---------: |\n",
        "| Linear     |  lin_0  |    120     |     84      |\n",
        "| ReLU       |      |            |             |\n",
        "| Linear     |  lin_1  |     84     |     10      |\n",
        "| LogSoftmax |      |            |             |\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6XYgiqIRjUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as funct\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr1a_m6SWQ6M",
        "colab_type": "text"
      },
      "source": [
        "Iniziamo definendo la **rete neurale** seguendo la tabella precedente. Osserviamo che il parametro *stride* misura di quanti pixel deve scorrere il filtro durante le operazioni di convoluzione e di pooling; il valore di default è $1$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQrkZdISBUV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeNet5(nn.Module):\n",
        "  def __init__(self):\n",
        "        super(LeNet5,self).__init__()\n",
        "\n",
        "        self.conv_0 = nn.Conv2d(1, 6, kernel_size=(5, 5),stride=1)\n",
        "        self.pool_0 = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
        "        self.conv_1 = nn.Conv2d(6,16,kernel_size=(5,5),stride=1)\n",
        "        self.pool_1 = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
        "        self.conv_2 = nn.Conv2d(16,120, kernel_size=(5,5), stride=1)\n",
        "        self.lin_0 = nn.Linear(120,84)\n",
        "        self.lin_1 = nn.Linear(84,10)\n",
        "\n",
        "  def forward(self,image):\n",
        "    out = funct.relu(self.conv_0(image))\n",
        "    out = funct.relu(self.conv_1(self.pool_0(out)))\n",
        "    out = funct.relu(self.conv_2(self.pool_1(out)))\n",
        "    out = out.view(image.shape[0], -1)\n",
        "    out = funct.relu(self.lin_0(out))\n",
        "    out = funct.log_softmax(self.lin_1(out),dim=-1)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuYz-35qhzaI",
        "colab_type": "text"
      },
      "source": [
        "Riassumiamo le caratteristiche della nostra rete neurale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWjOKdI504vV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MyLeNet = LeNet5()\n",
        "print(MyLeNet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EesafbsK1RHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "named_params = list(MyLeNet.named_parameters())\n",
        "print('Le entità addrestabili della rete sono:')\n",
        "for name, param in named_params:\n",
        "    print(\"  %s:\\t%s\" % (name, param.shape))\n",
        "print ('\\n Il numero totale di parametri addestrabili è', sum(p.numel() for p in MyLeNet.parameters() if p.requires_grad))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrJAKmmuhkEZ",
        "colab_type": "text"
      },
      "source": [
        "Testiamo la rete con un input casuale, sfruttando l'inizializzazione di default dei vari parametri addestrabili."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgMeLZz61XPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input = torch.randn(1, 1, 32, 32)  # batch_size, num_channels, height, width\n",
        "out = MyLeNet(input)\n",
        "print(\"Log-Probabilities: \\n%s\\n\" % out)\n",
        "print(\"Probabilities: \\n%s\\n\" % torch.exp(out))\n",
        "print(\"out.shape: \\n%s\" % (out.shape,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6Aqntu5h_ok",
        "colab_type": "text"
      },
      "source": [
        "Definiamo la **funzione di training**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EITH2CRF3FyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_cnn(model, train_loader, test_loader, device, num_epochs, lr=0.1):\n",
        "\n",
        "    train_acc_list = np.array([])\n",
        "    test_acc_list = np.array([])\n",
        "    time_list = np.array([])\n",
        "\n",
        "\n",
        "    # Ottimizzatore e funzione di errore\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(\"=\" * 40, \"Starting epoch %d\" % (epoch + 1), \"=\" * 40)\n",
        "        \n",
        "        model.train() # impostiamo la modalità addestramento al modulo.\n",
        "                \n",
        "        # cicli concatenati: per ogni batch andiamo ad aggiustare i pesi\n",
        "        for batch_idx, (data, labels) in enumerate(train_loader):\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            #stampiamo l'andamento ogni 75 batch \n",
        "            if batch_idx % 75 == 0:\n",
        "                print(\"Batch %d/%d, Loss=%.4f\" % (batch_idx, len(train_loader), loss.item()))\n",
        "        \n",
        "        # Compute the train and test accuracy at the end of each epoch\n",
        "        train_acc = accuracy(model, train_loader, device)\n",
        "        test_acc = accuracy(model, test_loader, device)\n",
        "\n",
        "        train_acc_list = np.append(train_acc_list, [train_acc])\n",
        "        test_acc_list = np.append(test_acc_list, [test_acc])\n",
        "        time_list = np.append(time_list, [epoch+1])\n",
        "\n",
        "    return train_acc_list, test_acc_list, time_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfTnxUvVpwZ9",
        "colab_type": "text"
      },
      "source": [
        "Definiamo una **metrica** di valutazione delle performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja7NUPt63HLX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(model, dataloader, device):\n",
        "  \n",
        "    model.eval() # impostiamo la modalità test al modulo.\n",
        "    \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    with torch.no_grad():  \n",
        "        for data, labels in dataloader:\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "            predictions = model(data).max(1)[1]  \n",
        "            num_correct += (predictions == labels).sum().item()\n",
        "            num_samples += predictions.shape[0]\n",
        "        \n",
        "    return num_correct / num_samples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUBN7WEqp5Fb",
        "colab_type": "text"
      },
      "source": [
        "Importiamo i **dati** e costruiamo i **batch**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF_KKSug3QTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "transformations = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_data = datasets.MNIST('./data', \n",
        "                            train = True, \n",
        "                            download = True,\n",
        "                            transform = transformations)\n",
        "\n",
        "test_data = datasets.MNIST('./data', \n",
        "                            train = False, \n",
        "                            download = True,\n",
        "                            transform = transformations)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=256, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1024, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_vdQ-EIqOkm",
        "colab_type": "text"
      },
      "source": [
        "Visualizziamo qualche esempio di addestamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1JMmUNm3XCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(16,9))\n",
        "data, target = next(iter(train_loader))\n",
        "for i in range(10):\n",
        "    img = data.squeeze(1)[i]\n",
        "    plt.subplot(1, 10, i+1)\n",
        "    plt.imshow(img, cmap=\"gray\", interpolation=\"none\")\n",
        "    plt.xlabel(target[i].item(), fontsize=18)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTe0JNizqpcu",
        "colab_type": "text"
      },
      "source": [
        "Eseguiamo la funzione di addestramento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYSXEgSk3dZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "MyLeNet = MyLeNet.to(device)\n",
        "\n",
        "y_1,y_2,x = train_cnn(MyLeNet, train_loader, test_loader, device, lr=2e-3, num_epochs=15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cT5vNjiKq6Vo",
        "colab_type": "text"
      },
      "source": [
        "Visualizziamo le **performance** ottenute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAkGGYR7pO6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot(x_axis,x_label,y_1_axis,y_1_label,curve_label_1,y_2_axis,y_2_label,curve_label_2 ):\n",
        "   plt.plot(x_axis, y_1_axis, label=curve_label_1)\n",
        "   plt.plot(x_axis, y_2_axis, label=curve_label_2)\n",
        "   plt.xlabel(x_label)\n",
        "   plt.ylabel(y_1_label)\n",
        "   plt.ylabel(y_2_label)\n",
        "   plt.legend(shadow=True)\n",
        "\n",
        "plot(x_axis=x,x_label=\"epoch\",\n",
        "     y_1_axis=y_1,y_1_label=\"accuracy\",curve_label_1=\"Train accuracy\",\n",
        "     y_2_axis=y_2,y_2_label=\"accuracy\",curve_label_2=\"Test accuracy\"\n",
        "     )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzxITMzyovjD",
        "colab_type": "text"
      },
      "source": [
        "Infine visualizziamo qualche **predizione** della nostra rete neurale sull'insieme di test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki6dH8_k3fvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_predictions(model, dataloader, device):\n",
        "    data, labels = next(iter(dataloader)) \n",
        "    data, labels = data[:10].to(device), labels[:10]\n",
        "    predictions = model(data).max(1)[1]\n",
        "    \n",
        "    predictions, data = predictions.cpu(), data.cpu()\n",
        "    \n",
        "    plt.figure(figsize=(16,9))\n",
        "    for i in range(10):\n",
        "        img = data.squeeze(1)[i]\n",
        "        plt.subplot(1, 10, i+1)\n",
        "        plt.imshow(img, cmap=\"gray\", interpolation=\"none\")\n",
        "        plt.xlabel(predictions[i].item(), fontsize=18)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])    \n",
        "    \n",
        "visualize_predictions(MyLeNet, test_loader, device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9J9XnlcpZuG",
        "colab_type": "text"
      },
      "source": [
        "**Osservazione**: Nella precedente funzione si fa uso degli **iteratori** per scorrere `dataloader`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wi8VbbpXqib0",
        "colab_type": "text"
      },
      "source": [
        "**Esercizio**: Ripetere la classificazione usando *VGG16* al posto di *LeNet-5*.\n",
        "\n",
        "[Very Deep Convolutional Networks for Large-Scale Visual Recognition](https://www.robots.ox.ac.uk/~vgg/research/very_deep/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBGrypEVrFYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}